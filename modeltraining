import os
import numpy as np
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from skimage import io, filters, morphology, measure, transform

def find_bounding_box_and_crop(image, max_aspect_ratio=5):
    inverted_image = 1 - image
    label_image = measure.label(inverted_image)
    regions = measure.regionprops(label_image)
    max_area = 0
    max_bbox = None
    for region in regions:
        if region.area > max_area and region.major_axis_length / region.minor_axis_length < max_aspect_ratio:
            max_area = region.area
            max_bbox = region.bbox
    min_row, min_col, max_row, max_col = max_bbox
    cropped_image = image[min_row:max_row, min_col:max_col]
    return cropped_image

def delete_outer_black_areas(image):
    inner_black_mask = morphology.binary_erosion(image)
    outer_black_mask = image & ~inner_black_mask
    cleaned_image = image.copy()
    cleaned_image[outer_black_mask] = 1
    return cleaned_image

def angle_image(image, angle_degrees):
    transformation_matrix = transform.AffineTransform(rotation=np.deg2rad(angle_degrees))
    angled_image = transform.warp(image, transformation_matrix)
    return angled_image

def flood_fill(image, row, col):
    stack = [(row, col)]
    while stack:
        r, c = stack.pop()
        if 0 <= r < image.shape[0] and 0 <= c < image.shape[1] and image[r, c] == 0:
            image[r, c] = 1
            stack.append((r + 1, c))
            stack.append((r - 1, c))
            stack.append((r, c + 1))
            stack.append((r, c - 1))

def replace_consecutive_zeros(image, threshold=30):
    cleaned_image = image.copy()
    for row in range(cleaned_image.shape[0]):
        count = 0
        for col in range(cleaned_image.shape[1]):
            if cleaned_image[row, col] == 0:
                count += 1
                if count >= threshold:
                    cleaned_image[row, col - count + 1:col + 1] = 1
                    for r in range(row, -1, -1):
                        if cleaned_image[r, col] == 0:
                            flood_fill(cleaned_image, r, col)
                        else:
                            break
                    for r in range(row + 1, cleaned_image.shape[0]):
                        if cleaned_image[r, col] == 0:
                            flood_fill(cleaned_image, r, col)
                        else:
                            break
            else:
                count = 0
    return cleaned_image

def save_character_matrix(character_image, filename):
    resized_character_image = transform.resize(character_image, (50, 50), anti_aliasing=False)
    np.savetxt(filename, resized_character_image.astype(int), fmt='%d')

image_path = '/content/numberplate1.jpg'
image = io.imread(image_path, as_gray=True)
cropped_image = find_bounding_box_and_crop(image)
cleaned_image = delete_outer_black_areas(cropped_image)
angled_image = angle_image(cleaned_image, angle_degrees=2)
binary_image = angled_image > filters.threshold_otsu(angled_image)
cleaned_binary_image = replace_consecutive_zeros(binary_image)
label_image = measure.label(cleaned_binary_image == 0)
num_characters = np.max(label_image)

regions = measure.regionprops(label_image)
for i, region in enumerate(regions):
    if region.area < 200:
        cleaned_binary_image[label_image == region.label] = 1
    else:
        character_matrix = cleaned_binary_image.copy()
        character_matrix[label_image != region.label] = 1
        min_row, min_col, max_row, max_col = region.bbox
        character_matrix = character_matrix[min_row:max_row, min_col:max_col]
        save_character_matrix(character_matrix, f'character_{i + 1}.txt')

# Save the modified binary image matrix to a text file
np.savetxt('cleaned_binary_matrix.txt', cleaned_binary_image.astype(int), fmt='%d')

# =============== TRAINING==============

# Step 1: Load data from directories
data_directory = 'D:\ICBT\ICBT Final Dissertation Project\System\TraininigSet'
characters = os.listdir(data_directory)

X = []
y = []

for character in characters:
    character_directory = os.path.join(data_directory, character)
    character_files = os.listdir(character_directory)
    for file in character_files:
        # Load matrix file and flatten it
        matrix = np.loadtxt(os.path.join(character_directory, file)).flatten()
        # Append matrix to feature array
        X.append(matrix)
        # Append label to target array
        y.append(character)

# Step 2: Label encoding
# Encode character labels into numerical values
label_mapping = {char: idx for idx, char in enumerate(set(y))}
y_encoded = [label_mapping[label] for label in y]

# Step 3: Initialize and train SVM model
svm_clf = SVC(kernel='linear', C=1.0)
svm_clf.fit(X, y_encoded)

# Step 4: Predict labels for training data
y_pred = svm_clf.predict(X)

# Step 5: Evaluate model
accuracy = accuracy_score(y_encoded, y_pred)
print("Accuracy:", accuracy)

# Step 6: Decode predicted labels back to characters
predicted_labels = [list(label_mapping.keys())[list(label_mapping.values()).index(label)] for label in y_pred]

print("Numerical labels:", y_pred)
# Step 7: Display output
print("Predicted labels:", predicted_labels)

import pickle

# Save the trained SVM model to a file
with open('svm_model.pkl', 'wb') as f:
    pickle.dump(svm_clf, f)

import os
import numpy as np
import pickle

# Define the label mapping
label_mapping = {'1': 6,'Y': 4,'F': 3,'B': 1,'8': 0,'7': 5,'5': 2}

# Load the SVM model from the pickle file
with open('svm_model.pkl', 'rb') as f:
    svm_model = pickle.load(f)

# Load the new matrix file
new_matrix_file = '/content/bikewithouthelmet_numberplate_character.txt'  # Replace 'new_matrix.txt' with the path to your new matrix file
new_matrix = np.loadtxt(new_matrix_file).flatten()

# Use the loaded model to predict the character
predicted_character_index = svm_model.predict([new_matrix])[0]

# Decode the predicted character index
predicted_character = list(label_mapping.keys())[list(label_mapping.values()).index(predicted_character_index)]

print("Predicted character:", predicted_character)